{"cells":[{"cell_type":"markdown","metadata":{"executionInfo":{"elapsed":14669,"status":"ok","timestamp":1647878285377,"user":{"displayName":"Sho Virtucio","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9AatE9KEktnILNDllMt0BeLYDfDn8ujor9yZV5Q=s64","userId":"00667323430306773467"},"user_tz":-540},"id":"CQBJ_Sj98vWc","outputId":"c006713a-7025-4edf-cd47-4cdf0868c024"},"source":["### 01. Connect to your Google Drive\n","\n","Run the code below to connect to your Google Drive folders.\n","You will be prompted for permissions to access your drive.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ofUhSq4EKcL","executionInfo":{"status":"ok","timestamp":1680556478385,"user_tz":240,"elapsed":30594,"user":{"displayName":"谢北辰","userId":"06281340701736441026"}},"outputId":"641ae892-64f0-4eb7-86c8-642995e97cab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Note: using Google CoLab\n"]}],"source":["try:\n","    from google.colab import drive\n","\n","    drive.mount(\"/content/drive\", force_remount=True)\n","    COLAB = True\n","    print(\"Note: using Google CoLab\")\n","except:\n","    print(\"Note: not using Google CoLab\")\n","    COLAB = False\n"]},{"cell_type":"markdown","metadata":{"id":"nu3Qo8mrEKcM"},"source":["### 02. Verify if GPUs are turned on and available\n","\n","If the `nvidia-smi` script does not return any GPUs, you need to turn on GPUs in:\n","\n","```\n","Menu -> Runtime -> Change runtime type -> Hardware Accelerator Dropdown -> select \"GPU\"\n","```"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J6eqGzEhEKcM","executionInfo":{"status":"ok","timestamp":1680556515065,"user_tz":240,"elapsed":1471,"user":{"displayName":"谢北辰","userId":"06281340701736441026"}},"outputId":"97689d48-a934-42c9-a94a-002d7c5f38ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Apr  3 21:15:13 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# Verify if GPUs are available\n","!nvidia-smi"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"CrPsvA9y81IK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680556598462,"user_tz":240,"elapsed":75111,"user":{"displayName":"谢北辰","userId":"06281340701736441026"}},"outputId":"9b7d993d-512a-4c6d-d8b9-2dadc49fa080"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.9.0\n","  Downloading torch-1.9.0-cp39-cp39-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.4/831.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.10.0\n","  Downloading torchvision-0.10.0-cp39-cp39-manylinux1_x86_64.whl (22.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.1/22.1 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.9.0) (4.5.0)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.10.0) (8.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.10.0) (1.22.4)\n","Installing collected packages: torch, torchvision\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.0.0+cu118\n","    Uninstalling torch-2.0.0+cu118:\n","      Successfully uninstalled torch-2.0.0+cu118\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.15.1+cu118\n","    Uninstalling torchvision-0.15.1+cu118:\n","      Successfully uninstalled torchvision-0.15.1+cu118\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.9.0 which is incompatible.\n","torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.9.0 which is incompatible.\n","torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.9.0 torchvision-0.10.0\n","Cloning into 'stylegan3'...\n","remote: Enumerating objects: 207, done.\u001b[K\n","remote: Total 207 (delta 0), reused 0 (delta 0), pack-reused 207\u001b[K\n","Receiving objects: 100% (207/207), 4.17 MiB | 18.49 MiB/s, done.\n","Resolving deltas: 100% (98/98), done.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ninja\n","  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ninja\n","Successfully installed ninja-1.11.1\n"]}],"source":["# Install dependencies and clone StyleGAN3\n","\n","!pip install torch==1.9.0 torchvision==0.10.0\n","!git clone https://github.com/NVlabs/stylegan3.git\n","!pip install ninja"]},{"cell_type":"code","source":["!pip install torch==1.9.0 torchvision==0.10.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xL8QfvBkyRxz","executionInfo":{"status":"ok","timestamp":1680419144802,"user_tz":240,"elapsed":3345,"user":{"displayName":"谢北辰","userId":"06281340701736441026"}},"outputId":"552f132a-8875-4925-9970-e7fb5d647bdf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.9/dist-packages (1.9.0)\n","Requirement already satisfied: torchvision==0.10.0 in /usr/local/lib/python3.9/dist-packages (0.10.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.9.0) (4.5.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.10.0) (1.22.4)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.10.0) (8.4.0)\n"]}]},{"cell_type":"code","source":["!pip install --upgrade torch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1iXj14D_SO9P","executionInfo":{"status":"ok","timestamp":1680461172690,"user_tz":240,"elapsed":99765,"user":{"displayName":"谢北辰","userId":"06281340701736441026"}},"outputId":"ca91de0c-737d-4518-bab7-a45143d78d1b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.9.0)\n","Collecting torch\n","  Downloading torch-2.0.0-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 KB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n","Collecting nvidia-cuda-cupti-cu11==11.7.101\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.10.7)\n","Collecting triton==2.0.0\n","  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n","Collecting nvidia-cudnn-cu11==8.5.0.96\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.6.1)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.40.0)\n","Collecting lit\n","  Downloading lit-16.0.0.tar.gz (144 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 KB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n","Building wheels for collected packages: lit\n","  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lit: filename=lit-16.0.0-py3-none-any.whl size=93601 sha256=49bc84ba99a2befbfdbb66bb2510421d814f563fb199f8892a95f443beaa61ce\n","  Stored in directory: /root/.cache/pip/wheels/c7/ee/80/1520ca86c3557f70e5504b802072f7fc3b0e2147f376b133ed\n","Successfully built lit\n","Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.9.0\n","    Uninstalling torch-1.9.0:\n","      Successfully uninstalled torch-1.9.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.10.0 requires torch==1.9.0, but you have torch 2.0.0 which is incompatible.\n","torchtext 0.14.1 requires torch==1.13.1, but you have torch 2.0.0 which is incompatible.\n","torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed lit-16.0.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 triton-2.0.0\n"]}]},{"cell_type":"code","source":["!pip install --upgrade torchvision"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BRi0tkSEXgB5","executionInfo":{"status":"ok","timestamp":1680462463662,"user_tz":240,"elapsed":6916,"user":{"displayName":"谢北辰","userId":"06281340701736441026"}},"outputId":"565c8681-d265-4540-eee5-655325b379cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.10.0)\n","Collecting torchvision\n","  Downloading torchvision-0.15.1-cp39-cp39-manylinux1_x86_64.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (3.1.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (3.10.7)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (10.2.10.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (2.14.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (4.5.0)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (10.9.0.58)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (11.7.101)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (3.0)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (2.0.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (11.7.99)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (11.7.91)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (1.11.1)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (11.4.0.1)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (11.10.3.66)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (8.5.0.96)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (11.7.4.91)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchvision) (67.6.1)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchvision) (0.40.0)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision) (16.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision) (3.25.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.0.0->torchvision) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch==2.0.0->torchvision) (1.3.0)\n","Installing collected packages: torchvision\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.10.0\n","    Uninstalling torchvision-0.10.0:\n","      Successfully uninstalled torchvision-0.10.0\n","Successfully installed torchvision-0.15.1\n"]}]},{"cell_type":"code","source":["!pip install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio===0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DqGe1ndPYcKm","executionInfo":{"status":"ok","timestamp":1680556745170,"user_tz":240,"elapsed":78065,"user":{"displayName":"谢北辰","userId":"06281340701736441026"}},"outputId":"0d85b149-16ce-4b1b-ce86-f1c141b18bcb"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n","Collecting torch==1.10.0+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torch-1.10.0%2Bcu113-cp39-cp39-linux_x86_64.whl (1821.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m924.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.11.1+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.11.1%2Bcu113-cp39-cp39-linux_x86_64.whl (24.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio===0.10.0+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.10.0%2Bcu113-cp39-cp39-linux_x86_64.whl (2.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.10.0+cu113) (4.5.0)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.11.1+cu113) (8.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.11.1+cu113) (1.22.4)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.9.0\n","    Uninstalling torch-1.9.0:\n","      Successfully uninstalled torch-1.9.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.10.0\n","    Uninstalling torchvision-0.10.0:\n","      Successfully uninstalled torchvision-0.10.0\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.0.1+cu118\n","    Uninstalling torchaudio-2.0.1+cu118:\n","      Successfully uninstalled torchaudio-2.0.1+cu118\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.10.0+cu113 which is incompatible.\n","torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.10.0+cu113 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.10.0+cu113 torchaudio-0.10.0+cu113 torchvision-0.11.1+cu113\n"]}]},{"cell_type":"code","source":["!pip install setuptools==59.5.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b_iBiQPvfdyh","executionInfo":{"status":"ok","timestamp":1680556777579,"user_tz":240,"elapsed":10585,"user":{"displayName":"谢北辰","userId":"06281340701736441026"}},"outputId":"c71f710b-372b-45d7-8b03-b1170188b490"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting setuptools==59.5.0\n","  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.4/952.4 KB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: setuptools\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 67.6.1\n","    Uninstalling setuptools-67.6.1:\n","      Successfully uninstalled setuptools-67.6.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\n","cvxpy 1.3.1 requires setuptools>65.5.1, but you have setuptools 59.5.0 which is incompatible.\n","arviz 0.15.1 requires setuptools>=60.0.0, but you have setuptools 59.5.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed setuptools-59.5.0\n"]}]},{"cell_type":"code","source":["from setuptools import distutils\n","from distutils.version import LooseVersion"],"metadata":{"id":"W0rP45Snyfql","executionInfo":{"status":"ok","timestamp":1680556781435,"user_tz":240,"elapsed":1058,"user":{"displayName":"谢北辰","userId":"06281340701736441026"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3UeIcOoeEKcN"},"source":["### 03. Create folders for training\n","\n","Create a folder structure in your Google Drive:\n","\n","```\n","├── stylegan\n","│   ├── images\n","│   │   ├── <Your dataset folder containing images with dimensions of power of 2 (ex. - 64x64, 128x128, 1024x1024)>\n","│   ├── datasets\n","│   ├── experiments\n","```\n","\n","You can use [ImageMagick's](https://imagemagick.org/) batch image processor script `mogrify` locally before uploading to Google Drive to make sure all your images\n","\n","Take note of your raw dataset folder name and put it in the `RAW_DATASET_FOLDER_NAME` variable below.\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Ry5U1Ke59tUt","executionInfo":{"status":"ok","timestamp":1680556808222,"user_tz":240,"elapsed":335,"user":{"displayName":"谢北辰","userId":"06281340701736441026"}}},"outputs":[],"source":["import os\n","\n","# Change this to your dataset folder name\n","RAW_DATASET_FOLDER_NAME = \"sneaker_images_3000\" \n","\n","STYLEGAN_ROOT_FOLDER = os.path.join(\n","    os.sep, \"content\", \"drive\", \"MyDrive\", \"sneakergan_small\"\n",")\n","RAW_DATASET_PATH = os.path.join(STYLEGAN_ROOT_FOLDER, \"images\", RAW_DATASET_FOLDER_NAME)\n","ZIP_DATASET_PATH = os.path.join(STYLEGAN_ROOT_FOLDER, \"datasets\", RAW_DATASET_FOLDER_NAME + \".zip\")\n","EXPERIMENTS_PATH = os.path.join(STYLEGAN_ROOT_FOLDER, \"experiments\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xw6WBYjt_H1R","outputId":"ce6092dc-aca3-4d5f-d298-0fdc4be91414","executionInfo":{"status":"ok","timestamp":1680458720944,"user_tz":240,"elapsed":175248,"user":{"displayName":"谢北辰","userId":"06281340701736441026"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["100% 3000/3000 [02:53<00:00, 17.26it/s]\n"]}],"source":["dataset_creation_cmd = f\"python /content/stylegan3/dataset_tool.py --source={RAW_DATASET_PATH} --dest={ZIP_DATASET_PATH} --resolution=256x256\"\n","!{dataset_creation_cmd}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WjAeDOEz_TcC","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["02295a24065c4c36965f316d937464a0","0634a25d86d74fa58f87484c944c1abb","ca311de5b67b4cc9ab138da37bc5b340","da9f391c1343488d8b41008ea3c26511","f4131d1291ed4a0a850e78a0f62a7af5","c53ace07076d4872abf02f2ba92cb6c1","9600bc71539a4bc092491cfc35064a06","a26e365bbb23411d88e20b2f39250f61","5e53376ae42b40998b0530f9a1730692","3a554de4b932461698b896fe70ca64f6","29dc5e69a0d547ae91512a8c63efd866"]},"executionInfo":{"status":"ok","timestamp":1680458747525,"user_tz":240,"elapsed":5996,"user":{"displayName":"谢北辰","userId":"06281340701736441026"}},"outputId":"80a867c7-9821-4ea6-d02b-d8b575a4fa5b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02295a24065c4c36965f316d937464a0"}},"metadata":{}}],"source":["# Verifies your dataset for inconsistent sizes and colour formats\n","# Script created by @jeffheaton\n","\n","from os import listdir\n","from os.path import isfile, join\n","import os\n","from PIL import Image\n","from tqdm.notebook import tqdm\n","\n","\n","files = [f for f in listdir(RAW_DATASET_PATH) if isfile(join(RAW_DATASET_PATH, f))]\n","\n","base_size = None\n","for file in tqdm(files):\n","    file2 = os.path.join(RAW_DATASET_PATH, file)\n","    img = Image.open(file2)\n","    sz = img.size\n","    if base_size and sz != base_size:\n","        print(f\"Inconsistant size: {file2}\")\n","    elif img.mode != \"RGB\":\n","        print(f\"Inconsistant color format: {file2}\")\n","    else:\n","        base_size = sz\n"]},{"cell_type":"markdown","metadata":{"id":"gthM9M-NEKcP"},"source":["### 04. Training\n","\n","You can play around with different configurations here. A few descriptions:\n","\n","- `CFG` - you can pick `stylegan3-t` (only designed for translation equivariance) or `stylegan3-r` (features high-quality, though not visually perfect rotation equivariance). More details in the [official NVIDIA StyleGAN3 documentation](https://nvlabs.github.io/stylegan3/)\n","- `BATCH_SIZE` - the number of samples that will be passed through to the network at one time\n","- `BATCH_GPU` - per-GPU batch size\n","- `GAMMA` - R1 regularization weight\n","- `SNAP` - number of epochs before saving a new checkpoint in the `experiments` folder on Google Drive (for Google Colab Free, it is recommended to keep this low, say `5` or `10`)\n","\n","You can refer to the [official documentation's recommended configurations](https://github.com/NVlabs/stylegan3/blob/main/docs/configs.md#recommended-configurations) to see more config parameters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wxnJPUw__bwQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680493897525,"user_tz":240,"elapsed":1109438,"user":{"displayName":"谢北辰","userId":"06281340701736441026"}},"outputId":"abdec615-b57b-4285-d19d-d545c3aafab7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training options:\n","{\n","  \"G_kwargs\": {\n","    \"class_name\": \"training.networks_stylegan3.Generator\",\n","    \"z_dim\": 512,\n","    \"w_dim\": 512,\n","    \"mapping_kwargs\": {\n","      \"num_layers\": 2\n","    },\n","    \"channel_base\": 32768,\n","    \"channel_max\": 512,\n","    \"magnitude_ema_beta\": 0.9988915792636801\n","  },\n","  \"D_kwargs\": {\n","    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n","    \"block_kwargs\": {\n","      \"freeze_layers\": 0\n","    },\n","    \"mapping_kwargs\": {},\n","    \"epilogue_kwargs\": {\n","      \"mbstd_group_size\": 4\n","    },\n","    \"channel_base\": 32768,\n","    \"channel_max\": 512\n","  },\n","  \"G_opt_kwargs\": {\n","    \"class_name\": \"torch.optim.Adam\",\n","    \"betas\": [\n","      0,\n","      0.99\n","    ],\n","    \"eps\": 1e-08,\n","    \"lr\": 0.0025\n","  },\n","  \"D_opt_kwargs\": {\n","    \"class_name\": \"torch.optim.Adam\",\n","    \"betas\": [\n","      0,\n","      0.99\n","    ],\n","    \"eps\": 1e-08,\n","    \"lr\": 0.002\n","  },\n","  \"loss_kwargs\": {\n","    \"class_name\": \"training.loss.StyleGAN2Loss\",\n","    \"r1_gamma\": 2.0\n","  },\n","  \"data_loader_kwargs\": {\n","    \"pin_memory\": true,\n","    \"prefetch_factor\": 2,\n","    \"num_workers\": 1\n","  },\n","  \"training_set_kwargs\": {\n","    \"class_name\": \"training.dataset.ImageFolderDataset\",\n","    \"path\": \"/content/drive/MyDrive/sneakergan_small/datasets/sneaker_images_3000.zip\",\n","    \"use_labels\": false,\n","    \"max_size\": 3000,\n","    \"xflip\": false,\n","    \"resolution\": 256,\n","    \"random_seed\": 0\n","  },\n","  \"num_gpus\": 1,\n","  \"batch_size\": 32,\n","  \"batch_gpu\": 16,\n","  \"metrics\": [\n","    \"fid50k_full\"\n","  ],\n","  \"total_kimg\": 25000,\n","  \"kimg_per_tick\": 4,\n","  \"image_snapshot_ticks\": 10,\n","  \"network_snapshot_ticks\": 10,\n","  \"random_seed\": 0,\n","  \"ema_kimg\": 10.0,\n","  \"augment_kwargs\": {\n","    \"class_name\": \"training.augment.AugmentPipe\",\n","    \"xflip\": 1,\n","    \"rotate90\": 1,\n","    \"xint\": 1,\n","    \"scale\": 1,\n","    \"rotate\": 1,\n","    \"aniso\": 1,\n","    \"xfrac\": 1,\n","    \"brightness\": 1,\n","    \"contrast\": 1,\n","    \"lumaflip\": 1,\n","    \"hue\": 1,\n","    \"saturation\": 1\n","  },\n","  \"ada_target\": 0.6,\n","  \"run_dir\": \"/content/drive/MyDrive/sneakergan_small/experiments/00005-stylegan3-t-sneaker_images_3000-gpus1-batch32-gamma2\"\n","}\n","\n","Output directory:    /content/drive/MyDrive/sneakergan_small/experiments/00005-stylegan3-t-sneaker_images_3000-gpus1-batch32-gamma2\n","Number of GPUs:      1\n","Batch size:          32 images\n","Training duration:   25000 kimg\n","Dataset path:        /content/drive/MyDrive/sneakergan_small/datasets/sneaker_images_3000.zip\n","Dataset size:        3000 images\n","Dataset resolution:  256\n","Dataset labels:      False\n","Dataset x-flips:     False\n","\n","Creating output directory...\n","Launching processes...\n","Loading training set...\n","\n","Num images:  3000\n","Image shape: [3, 256, 256]\n","Label shape: [0]\n","\n","Constructing networks...\n","Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n","Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n","\n","Generator                     Parameters  Buffers  Output shape         Datatype\n","---                           ---         ---      ---                  ---     \n","mapping.fc0                   262656      -        [16, 512]            float32 \n","mapping.fc1                   262656      -        [16, 512]            float32 \n","mapping                       -           512      [16, 16, 512]        float32 \n","synthesis.input.affine        2052        -        [16, 4]              float32 \n","synthesis.input               262144      1545     [16, 512, 36, 36]    float32 \n","synthesis.L0_36_512.affine    262656      -        [16, 512]            float32 \n","synthesis.L0_36_512           2359808     25       [16, 512, 36, 36]    float32 \n","synthesis.L1_36_512.affine    262656      -        [16, 512]            float32 \n","synthesis.L1_36_512           2359808     25       [16, 512, 36, 36]    float32 \n","synthesis.L2_36_512.affine    262656      -        [16, 512]            float32 \n","synthesis.L2_36_512           2359808     25       [16, 512, 36, 36]    float32 \n","synthesis.L3_52_512.affine    262656      -        [16, 512]            float32 \n","synthesis.L3_52_512           2359808     37       [16, 512, 52, 52]    float16 \n","synthesis.L4_52_512.affine    262656      -        [16, 512]            float32 \n","synthesis.L4_52_512           2359808     25       [16, 512, 52, 52]    float16 \n","synthesis.L5_84_512.affine    262656      -        [16, 512]            float32 \n","synthesis.L5_84_512           2359808     37       [16, 512, 84, 84]    float16 \n","synthesis.L6_84_512.affine    262656      -        [16, 512]            float32 \n","synthesis.L6_84_512           2359808     25       [16, 512, 84, 84]    float16 \n","synthesis.L7_148_512.affine   262656      -        [16, 512]            float32 \n","synthesis.L7_148_512          2359808     37       [16, 512, 148, 148]  float16 \n","synthesis.L8_148_512.affine   262656      -        [16, 512]            float32 \n","synthesis.L8_148_512          2359808     25       [16, 512, 148, 148]  float16 \n","synthesis.L9_148_362.affine   262656      -        [16, 512]            float32 \n","synthesis.L9_148_362          1668458     25       [16, 362, 148, 148]  float16 \n","synthesis.L10_276_256.affine  185706      -        [16, 362]            float32 \n","synthesis.L10_276_256         834304      37       [16, 256, 276, 276]  float16 \n","synthesis.L11_276_181.affine  131328      -        [16, 256]            float32 \n","synthesis.L11_276_181         417205      25       [16, 181, 276, 276]  float16 \n","synthesis.L12_276_128.affine  92853       -        [16, 181]            float32 \n","synthesis.L12_276_128         208640      25       [16, 128, 276, 276]  float16 \n","synthesis.L13_256_128.affine  65664       -        [16, 128]            float32 \n","synthesis.L13_256_128         147584      25       [16, 128, 256, 256]  float16 \n","synthesis.L14_256_3.affine    65664       -        [16, 128]            float32 \n","synthesis.L14_256_3           387         1        [16, 3, 256, 256]    float16 \n","synthesis                     -           -        [16, 3, 256, 256]    float32 \n","---                           ---         ---      ---                  ---     \n","Total                         28472133    2456     -                    -       \n","\n","Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n","\n","Discriminator  Parameters  Buffers  Output shape         Datatype\n","---            ---         ---      ---                  ---     \n","b256.fromrgb   512         16       [16, 128, 256, 256]  float16 \n","b256.skip      32768       16       [16, 256, 128, 128]  float16 \n","b256.conv0     147584      16       [16, 128, 256, 256]  float16 \n","b256.conv1     295168      16       [16, 256, 128, 128]  float16 \n","b256           -           16       [16, 256, 128, 128]  float16 \n","b128.skip      131072      16       [16, 512, 64, 64]    float16 \n","b128.conv0     590080      16       [16, 256, 128, 128]  float16 \n","b128.conv1     1180160     16       [16, 512, 64, 64]    float16 \n","b128           -           16       [16, 512, 64, 64]    float16 \n","b64.skip       262144      16       [16, 512, 32, 32]    float16 \n","b64.conv0      2359808     16       [16, 512, 64, 64]    float16 \n","b64.conv1      2359808     16       [16, 512, 32, 32]    float16 \n","b64            -           16       [16, 512, 32, 32]    float16 \n","b32.skip       262144      16       [16, 512, 16, 16]    float16 \n","b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n","b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n","b32            -           16       [16, 512, 16, 16]    float16 \n","b16.skip       262144      16       [16, 512, 8, 8]      float32 \n","b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n","b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n","b16            -           16       [16, 512, 8, 8]      float32 \n","b8.skip        262144      16       [16, 512, 4, 4]      float32 \n","b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n","b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n","b8             -           16       [16, 512, 4, 4]      float32 \n","b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n","b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n","b4.fc          4194816     -        [16, 512]            float32 \n","b4.out         513         -        [16, 1]              float32 \n","---            ---         ---      ---                  ---     \n","Total          28864129    416      -                    -       \n","\n","Setting up augmentation...\n","Distributing across 1 GPUs...\n","Setting up training phases...\n","Exporting sample images...\n","Initializing logs...\n","2023-04-02 19:44:02.143095: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-04-02 19:44:03.998921: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Training for 25000 kimg...\n","\n","tick 0     kimg 0.0      time 2m 57s       sec/tick 99.4    sec/kimg 3106.98 maintenance 77.1   cpumem 5.45   gpumem 10.67  reserved 12.55  augment 0.000\n","Evaluating metrics...\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","{\"results\": {\"fid50k_full\": 459.81349558629694}, \"metric\": \"fid50k_full\", \"total_time\": 3150.260125875473, \"total_time_str\": \"52m 30s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1680467934.9544709}\n","tick 1     kimg 4.0      time 1h 20m 13s   sec/tick 1447.2  sec/kimg 361.79  maintenance 3189.5 cpumem 5.97   gpumem 9.69   reserved 10.57  augment 0.005\n","tick 2     kimg 8.0      time 1h 44m 16s   sec/tick 1443.0  sec/kimg 360.74  maintenance 0.4    cpumem 5.97   gpumem 9.69   reserved 10.58  augment 0.011\n","tick 3     kimg 12.0     time 2h 08m 34s   sec/tick 1457.2  sec/kimg 364.30  maintenance 0.3    cpumem 5.97   gpumem 9.69   reserved 10.58  augment 0.014\n","tick 4     kimg 16.0     time 2h 32m 50s   sec/tick 1456.0  sec/kimg 364.01  maintenance 0.0    cpumem 5.88   gpumem 9.70   reserved 10.58  augment 0.021\n","tick 5     kimg 20.0     time 2h 57m 07s   sec/tick 1457.0  sec/kimg 364.26  maintenance 0.4    cpumem 5.88   gpumem 9.69   reserved 10.58  augment 0.028\n","tick 6     kimg 24.0     time 3h 21m 21s   sec/tick 1453.4  sec/kimg 363.34  maintenance 0.4    cpumem 5.88   gpumem 9.69   reserved 10.58  augment 0.036\n","tick 7     kimg 28.0     time 3h 45m 34s   sec/tick 1452.9  sec/kimg 363.23  maintenance 0.4    cpumem 5.88   gpumem 9.69   reserved 10.58  augment 0.043\n","tick 8     kimg 32.0     time 4h 09m 48s   sec/tick 1454.0  sec/kimg 363.50  maintenance 0.0    cpumem 5.88   gpumem 9.69   reserved 10.58  augment 0.051\n","tick 9     kimg 36.0     time 4h 34m 00s   sec/tick 1450.8  sec/kimg 362.69  maintenance 0.4    cpumem 5.88   gpumem 9.75   reserved 10.58  augment 0.057\n","tick 10    kimg 40.0     time 4h 58m 00s   sec/tick 1440.5  sec/kimg 360.11  maintenance 0.4    cpumem 5.88   gpumem 9.74   reserved 10.58  augment 0.065\n","Evaluating metrics...\n","{\"results\": {\"fid50k_full\": 332.0690799608113}, \"metric\": \"fid50k_full\", \"total_time\": 3108.7345378398895, \"total_time_str\": \"51m 49s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000040.pkl\", \"timestamp\": 1680485590.1398594}\n","tick 11    kimg 44.0     time 6h 14m 12s   sec/tick 1431.2  sec/kimg 357.81  maintenance 3140.8 cpumem 5.88   gpumem 9.72   reserved 10.58  augment 0.072\n","tick 12    kimg 48.0     time 6h 38m 03s   sec/tick 1430.9  sec/kimg 357.72  maintenance 0.0    cpumem 5.88   gpumem 9.71   reserved 10.58  augment 0.080\n","tick 13    kimg 52.0     time 7h 01m 53s   sec/tick 1429.8  sec/kimg 357.46  maintenance 0.3    cpumem 5.88   gpumem 9.73   reserved 10.58  augment 0.084\n","tick 14    kimg 56.0     time 7h 25m 44s   sec/tick 1430.6  sec/kimg 357.64  maintenance 0.4    cpumem 5.88   gpumem 9.74   reserved 10.58  augment 0.090\n","tick 15    kimg 60.0     time 7h 49m 38s   sec/tick 1433.4  sec/kimg 358.35  maintenance 0.4    cpumem 5.88   gpumem 9.74   reserved 10.58  augment 0.097\n","Traceback (most recent call last):\n","\n","Exception ignored in: Exception ignored in sys.unraisablehook"]}],"source":["import os\n","\n","# Modify these to suit your needs\n","CFG = \"stylegan3-t\"\n","BATCH_SIZE = 32\n","BATCH_GPU = 16\n","GAMMA = 2\n","SNAP = 10\n","\n","# Build the command and run it\n","cmd = f\"/usr/bin/python3 /content/stylegan3/train.py --outdir={EXPERIMENTS_PATH} --data={ZIP_DATASET_PATH} --cfg={CFG} --gpus=1 --workers=1 --batch={BATCH_SIZE} --batch-gpu={BATCH_GPU} --gamma={GAMMA} --snap={SNAP}\"\n","!{cmd}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RB2juHc8AVI-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"16fffdfb-2f2e-41b6-e3a7-abd237ef316d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training options:\n","{\n","  \"G_kwargs\": {\n","    \"class_name\": \"training.networks_stylegan3.Generator\",\n","    \"z_dim\": 512,\n","    \"w_dim\": 512,\n","    \"mapping_kwargs\": {\n","      \"num_layers\": 2\n","    },\n","    \"channel_base\": 32768,\n","    \"channel_max\": 512,\n","    \"magnitude_ema_beta\": 0.9988915792636801\n","  },\n","  \"D_kwargs\": {\n","    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n","    \"block_kwargs\": {\n","      \"freeze_layers\": 0\n","    },\n","    \"mapping_kwargs\": {},\n","    \"epilogue_kwargs\": {\n","      \"mbstd_group_size\": 4\n","    },\n","    \"channel_base\": 32768,\n","    \"channel_max\": 512\n","  },\n","  \"G_opt_kwargs\": {\n","    \"class_name\": \"torch.optim.Adam\",\n","    \"betas\": [\n","      0,\n","      0.99\n","    ],\n","    \"eps\": 1e-08,\n","    \"lr\": 0.0025\n","  },\n","  \"D_opt_kwargs\": {\n","    \"class_name\": \"torch.optim.Adam\",\n","    \"betas\": [\n","      0,\n","      0.99\n","    ],\n","    \"eps\": 1e-08,\n","    \"lr\": 0.002\n","  },\n","  \"loss_kwargs\": {\n","    \"class_name\": \"training.loss.StyleGAN2Loss\",\n","    \"r1_gamma\": 2.0,\n","    \"blur_init_sigma\": 0\n","  },\n","  \"data_loader_kwargs\": {\n","    \"pin_memory\": true,\n","    \"prefetch_factor\": 2,\n","    \"num_workers\": 1\n","  },\n","  \"training_set_kwargs\": {\n","    \"class_name\": \"training.dataset.ImageFolderDataset\",\n","    \"path\": \"/content/drive/MyDrive/sneakergan_small/datasets/sneaker_images_3000.zip\",\n","    \"use_labels\": false,\n","    \"max_size\": 3000,\n","    \"xflip\": false,\n","    \"resolution\": 256,\n","    \"random_seed\": 0\n","  },\n","  \"num_gpus\": 1,\n","  \"batch_size\": 32,\n","  \"batch_gpu\": 16,\n","  \"metrics\": [\n","    \"fid50k_full\"\n","  ],\n","  \"total_kimg\": 25000,\n","  \"kimg_per_tick\": 4,\n","  \"image_snapshot_ticks\": 5,\n","  \"network_snapshot_ticks\": 5,\n","  \"random_seed\": 0,\n","  \"ema_kimg\": 10.0,\n","  \"augment_kwargs\": {\n","    \"class_name\": \"training.augment.AugmentPipe\",\n","    \"xflip\": 1,\n","    \"rotate90\": 1,\n","    \"xint\": 1,\n","    \"scale\": 1,\n","    \"rotate\": 1,\n","    \"aniso\": 1,\n","    \"xfrac\": 1,\n","    \"brightness\": 1,\n","    \"contrast\": 1,\n","    \"lumaflip\": 1,\n","    \"hue\": 1,\n","    \"saturation\": 1\n","  },\n","  \"ada_target\": 0.6,\n","  \"resume_pkl\": \"/content/drive/MyDrive/sneakergan_small/experiments/00006-stylegan3-t-sneaker_images_3000-gpus1-batch32-gamma2/network-snapshot-000080.pkl\",\n","  \"ada_kimg\": 100,\n","  \"ema_rampup\": null,\n","  \"run_dir\": \"/content/drive/MyDrive/sneakergan_small/experiments/00007-stylegan3-t-sneaker_images_3000-gpus1-batch32-gamma2\"\n","}\n","\n","Output directory:    /content/drive/MyDrive/sneakergan_small/experiments/00007-stylegan3-t-sneaker_images_3000-gpus1-batch32-gamma2\n","Number of GPUs:      1\n","Batch size:          32 images\n","Training duration:   25000 kimg\n","Dataset path:        /content/drive/MyDrive/sneakergan_small/datasets/sneaker_images_3000.zip\n","Dataset size:        3000 images\n","Dataset resolution:  256\n","Dataset labels:      False\n","Dataset x-flips:     False\n","\n","Creating output directory...\n","Launching processes...\n","Loading training set...\n","\n","Num images:  3000\n","Image shape: [3, 256, 256]\n","Label shape: [0]\n","\n","Constructing networks...\n","Resuming from \"/content/drive/MyDrive/sneakergan_small/experiments/00006-stylegan3-t-sneaker_images_3000-gpus1-batch32-gamma2/network-snapshot-000080.pkl\"\n","Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n","Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n","\n","Generator                     Parameters  Buffers  Output shape         Datatype\n","---                           ---         ---      ---                  ---     \n","mapping.fc0                   262656      -        [16, 512]            float32 \n","mapping.fc1                   262656      -        [16, 512]            float32 \n","mapping                       -           512      [16, 16, 512]        float32 \n","synthesis.input.affine        2052        -        [16, 4]              float32 \n","synthesis.input               262144      1545     [16, 512, 36, 36]    float32 \n","synthesis.L0_36_512.affine    262656      -        [16, 512]            float32 \n","synthesis.L0_36_512           2359808     25       [16, 512, 36, 36]    float32 \n","synthesis.L1_36_512.affine    262656      -        [16, 512]            float32 \n","synthesis.L1_36_512           2359808     25       [16, 512, 36, 36]    float32 \n","synthesis.L2_36_512.affine    262656      -        [16, 512]            float32 \n","synthesis.L2_36_512           2359808     25       [16, 512, 36, 36]    float32 \n","synthesis.L3_52_512.affine    262656      -        [16, 512]            float32 \n","synthesis.L3_52_512           2359808     37       [16, 512, 52, 52]    float16 \n","synthesis.L4_52_512.affine    262656      -        [16, 512]            float32 \n","synthesis.L4_52_512           2359808     25       [16, 512, 52, 52]    float16 \n","synthesis.L5_84_512.affine    262656      -        [16, 512]            float32 \n","synthesis.L5_84_512           2359808     37       [16, 512, 84, 84]    float16 \n","synthesis.L6_84_512.affine    262656      -        [16, 512]            float32 \n","synthesis.L6_84_512           2359808     25       [16, 512, 84, 84]    float16 \n","synthesis.L7_148_512.affine   262656      -        [16, 512]            float32 \n","synthesis.L7_148_512          2359808     37       [16, 512, 148, 148]  float16 \n","synthesis.L8_148_512.affine   262656      -        [16, 512]            float32 \n","synthesis.L8_148_512          2359808     25       [16, 512, 148, 148]  float16 \n","synthesis.L9_148_362.affine   262656      -        [16, 512]            float32 \n","synthesis.L9_148_362          1668458     25       [16, 362, 148, 148]  float16 \n","synthesis.L10_276_256.affine  185706      -        [16, 362]            float32 \n","synthesis.L10_276_256         834304      37       [16, 256, 276, 276]  float16 \n","synthesis.L11_276_181.affine  131328      -        [16, 256]            float32 \n","synthesis.L11_276_181         417205      25       [16, 181, 276, 276]  float16 \n","synthesis.L12_276_128.affine  92853       -        [16, 181]            float32 \n","synthesis.L12_276_128         208640      25       [16, 128, 276, 276]  float16 \n","synthesis.L13_256_128.affine  65664       -        [16, 128]            float32 \n","synthesis.L13_256_128         147584      25       [16, 128, 256, 256]  float16 \n","synthesis.L14_256_3.affine    65664       -        [16, 128]            float32 \n","synthesis.L14_256_3           387         1        [16, 3, 256, 256]    float16 \n","synthesis                     -           -        [16, 3, 256, 256]    float32 \n","---                           ---         ---      ---                  ---     \n","Total                         28472133    2456     -                    -       \n","\n","Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n","\n","Discriminator  Parameters  Buffers  Output shape         Datatype\n","---            ---         ---      ---                  ---     \n","b256.fromrgb   512         16       [16, 128, 256, 256]  float16 \n","b256.skip      32768       16       [16, 256, 128, 128]  float16 \n","b256.conv0     147584      16       [16, 128, 256, 256]  float16 \n","b256.conv1     295168      16       [16, 256, 128, 128]  float16 \n","b256           -           16       [16, 256, 128, 128]  float16 \n","b128.skip      131072      16       [16, 512, 64, 64]    float16 \n","b128.conv0     590080      16       [16, 256, 128, 128]  float16 \n","b128.conv1     1180160     16       [16, 512, 64, 64]    float16 \n","b128           -           16       [16, 512, 64, 64]    float16 \n","b64.skip       262144      16       [16, 512, 32, 32]    float16 \n","b64.conv0      2359808     16       [16, 512, 64, 64]    float16 \n","b64.conv1      2359808     16       [16, 512, 32, 32]    float16 \n","b64            -           16       [16, 512, 32, 32]    float16 \n","b32.skip       262144      16       [16, 512, 16, 16]    float16 \n","b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n","b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n","b32            -           16       [16, 512, 16, 16]    float16 \n","b16.skip       262144      16       [16, 512, 8, 8]      float32 \n","b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n","b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n","b16            -           16       [16, 512, 8, 8]      float32 \n","b8.skip        262144      16       [16, 512, 4, 4]      float32 \n","b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n","b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n","b8             -           16       [16, 512, 4, 4]      float32 \n","b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n","b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n","b4.fc          4194816     -        [16, 512]            float32 \n","b4.out         513         -        [16, 1]              float32 \n","---            ---         ---      ---                  ---     \n","Total          28864129    416      -                    -       \n","\n","Setting up augmentation...\n","Distributing across 1 GPUs...\n","Setting up training phases...\n","Exporting sample images...\n","Initializing logs...\n","2023-04-03 21:26:36.392956: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-04-03 21:26:38.442464: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Training for 25000 kimg...\n","\n","tick 0     kimg 0.0      time 7m 04s       sec/tick 103.6   sec/kimg 3236.83 maintenance 320.2  cpumem 5.79   gpumem 10.76  reserved 12.55  augment 0.000\n","Evaluating metrics...\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","{\"results\": {\"fid50k_full\": 237.38794798599946}, \"metric\": \"fid50k_full\", \"total_time\": 3141.1829042434692, \"total_time_str\": \"52m 21s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1680560482.6114302}\n"]}],"source":["# Resume Training\n","\n","import os\n","\n","# Modify these to suit your needs\n","CHECKPOINT_FOLDER = \"00006-stylegan3-t-sneaker_images_3000-gpus1-batch32-gamma2\"\n","NETWORK = \"network-snapshot-000080.pkl\"\n","RESUME = os.path.join(EXPERIMENTS_PATH, CHECKPOINT_FOLDER, NETWORK)\n","\n","# Modify these to suit your needs\n","CFG = \"stylegan3-t\"\n","BATCH_SIZE = 32\n","BATCH_GPU = 16\n","GAMMA = 2\n","SNAP = 5\n","\n","# Build the command and run it\n","cmd = f\"/usr/bin/python3 /content/stylegan3/train.py --resume={RESUME} --outdir={EXPERIMENTS_PATH} --data={ZIP_DATASET_PATH} --cfg={CFG} --gpus=1 --workers=1 --batch={BATCH_SIZE} --batch-gpu={BATCH_GPU} --gamma={GAMMA} --snap={SNAP}\"\n","!{cmd}"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"02295a24065c4c36965f316d937464a0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0634a25d86d74fa58f87484c944c1abb","IPY_MODEL_ca311de5b67b4cc9ab138da37bc5b340","IPY_MODEL_da9f391c1343488d8b41008ea3c26511"],"layout":"IPY_MODEL_f4131d1291ed4a0a850e78a0f62a7af5"}},"0634a25d86d74fa58f87484c944c1abb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c53ace07076d4872abf02f2ba92cb6c1","placeholder":"​","style":"IPY_MODEL_9600bc71539a4bc092491cfc35064a06","value":"100%"}},"ca311de5b67b4cc9ab138da37bc5b340":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a26e365bbb23411d88e20b2f39250f61","max":3000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5e53376ae42b40998b0530f9a1730692","value":3000}},"da9f391c1343488d8b41008ea3c26511":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a554de4b932461698b896fe70ca64f6","placeholder":"​","style":"IPY_MODEL_29dc5e69a0d547ae91512a8c63efd866","value":" 3000/3000 [00:05&lt;00:00, 808.41it/s]"}},"f4131d1291ed4a0a850e78a0f62a7af5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c53ace07076d4872abf02f2ba92cb6c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9600bc71539a4bc092491cfc35064a06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a26e365bbb23411d88e20b2f39250f61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e53376ae42b40998b0530f9a1730692":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3a554de4b932461698b896fe70ca64f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29dc5e69a0d547ae91512a8c63efd866":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}